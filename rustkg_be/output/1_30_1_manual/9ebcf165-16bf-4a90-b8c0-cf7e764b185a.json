{"stability":{"stable since":"1.0.0"},"apiName":"pointer","apiType":"primitive","apiDocumentation":{"apiDescription":["Raw, unsafe pointers, *const T, and *mut T.","See also the std::ptr module.","Working with raw pointers in Rust is uncommon, typically limited to a few patterns.","Use the null and null_mut functions to create null pointers, and the is_null method of the *const T and *mut T types to check for null. The *const T and *mut T types also define the offset method, for pointer math.","Common ways to create raw pointers","1. Coerce a reference (&T) or mutable reference (&mut T).","let my_num: i32 = 10; let my_num_ptr: *const i32 = &my_num; let mut my_speed: i32 = 88; let my_speed_ptr: *mut i32 = &mut my_speed;","To get a pointer to a boxed value, dereference the box:","let my_num: Box<i32> = Box::new(10); let my_num_ptr: *const i32 = &*my_num; let mut my_speed: Box<i32> = Box::new(88); let my_speed_ptr: *mut i32 = &mut *my_speed;","This does not take ownership of the original allocation and requires no resource management later, but you must not use the pointer after its lifetime.","2. Consume a box (Box<T>).","The into_raw function consumes a box and returns the raw pointer. It doesn't destroy T or deallocate any memory.","let my_speed: Box<i32> = Box::new(88); let my_speed: *mut i32 = Box::into_raw(my_speed); // By taking ownership of the original `Box<T>` though // we are obligated to put it together later to be destroyed. unsafe { drop(Box::from_raw(my_speed)); }","Note that here the call to drop is for clarity - it indicates that we are done with the given value and it should be destroyed.","3. Get it from C.","extern crate libc; use std::mem; fn main() { unsafe { let my_num: *mut i32 = libc::malloc(mem::size_of::<i32>()) as *mut i32; if my_num.is_null() { panic!(\"failed to allocate memory\"); } libc::free(my_num as *mut libc::c_void); } }","Usually you wouldn't literally use malloc and free from Rust, but C APIs hand out a lot of pointers generally, so are a common source of raw pointers in Rust."]},"trait implementations":[{"name":"impl<T> std::hash::Hash for *const T where T: ?std::marker::Sized","stable since":"1.0.0"},{"name":"impl<T> std::hash::Hash for *mut T where T: ?std::marker::Sized","stable since":"1.0.0"},{"name":"impl<T> std::clone::Clone for *const T where T: ?std::marker::Sized","stable since":"1.0.0"},{"name":"impl<T> std::clone::Clone for *mut T where T: ?std::marker::Sized","stable since":"1.0.0"},{"name":"impl<T> std::cmp::PartialOrd<*mut T> for *mut T where T: ?std::marker::Sized","stable since":"1.0.0"},{"name":"impl<T> std::cmp::PartialOrd<*const T> for *const T where T: ?std::marker::Sized","stable since":"1.0.0"},{"name":"impl<T> std::cmp::Ord for *mut T where T: ?std::marker::Sized","stable since":"1.0.0"},{"name":"impl<T> std::cmp::Ord for *const T where T: ?std::marker::Sized","stable since":"1.0.0"},{"name":"impl<T> std::fmt::Pointer for *const T where T: ?std::marker::Sized","stable since":"1.0.0"},{"name":"impl<T> std::fmt::Pointer for *mut T where T: ?std::marker::Sized","stable since":"1.0.0"},{"name":"impl<T> std::fmt::Debug for *const T where T: ?std::marker::Sized","stable since":"1.0.0"},{"name":"impl<T> std::fmt::Debug for *mut T where T: ?std::marker::Sized","stable since":"1.0.0"},{"name":"impl<T> std::cmp::Eq for *mut T where T: ?std::marker::Sized","stable since":"1.0.0"},{"name":"impl<T> std::cmp::Eq for *const T where T: ?std::marker::Sized","stable since":"1.0.0"},{"name":"impl<T, U> std::ops::CoerceUnsized<*const U> for *mut T where T: std::marker::Unsize<U> + ?std::marker::Sized, U: ?std::marker::Sized","stable since":"1.0.0"},{"name":"impl<T, U> std::ops::CoerceUnsized<*const U> for *const T where T: std::marker::Unsize<U> + ?std::marker::Sized, U: ?std::marker::Sized","stable since":"1.0.0"},{"name":"impl<T, U> std::ops::CoerceUnsized<*mut U> for *mut T where T: std::marker::Unsize<U> + ?std::marker::Sized, U: ?std::marker::Sized","stable since":"1.0.0"},{"name":"impl<T> std::cmp::PartialEq<*mut T> for *mut T where T: ?std::marker::Sized","stable since":"1.0.0"},{"name":"impl<T> std::cmp::PartialEq<*const T> for *const T where T: ?std::marker::Sized","stable since":"1.0.0"},{"name":"impl<T> std::marker::Copy for *const T where T: ?std::marker::Sized","stable since":"1.0.0"},{"name":"impl<T> std::marker::Copy for *mut T where T: ?std::marker::Sized","stable since":"1.0.0"},{"name":"impl<T> !std::marker::Sync for *mut T where T: ?std::marker::Sized","stable since":"1.0.0"},{"name":"impl<T> !std::marker::Sync for *const T where T: ?std::marker::Sized","stable since":"1.0.0"},{"name":"impl<T> !std::marker::Send for *mut T where T: ?std::marker::Sized","stable since":"1.0.0"},{"name":"impl<T> !std::marker::Send for *const T where T: ?std::marker::Sized","stable since":"1.0.0"},{"name":"impl<T: std::panic::RefUnwindSafe + ?std::marker::Sized> std::panic::UnwindSafe for *const T","stable since":"1.9.0"},{"name":"impl<T: std::panic::RefUnwindSafe + ?std::marker::Sized> std::panic::UnwindSafe for *mut T","stable since":"1.9.0"}],"methods":[{"name":"pub fn is_null(self) -> bool","details":{"description":["Returns true if the pointer is null.","Note that unsized types have many possible null pointers, as only the raw data pointer is considered, not their length, vtable, etc. Therefore, two pointers that are null may still not compare equal to each other."],"example":["Basic usage:","let s: &str = \"Follow the rabbit\";\nlet ptr: *const u8 = s.as_ptr();\nassert!(!ptr.is_null());"]}},{"name":"pub unsafe fn as_ref<'a>(self) -> Option<&'a T>","details":{"description":["Returns None if the pointer is null, or else returns a reference to the value wrapped in Some.","Safety","While this method and its mutable counterpart are useful for null-safety, it is important to note that this is still an unsafe operation because the returned value could be pointing to invalid memory.","Additionally, the lifetime 'a returned is arbitrarily chosen and does not necessarily reflect the actual lifetime of the data."],"example":["Basic usage:","let ptr: *const u8 = &10u8 as *const u8;\n\nunsafe {\n    if let Some(val_back) = ptr.as_ref() {\n        println!(\"We got back the value: {}!\", val_back);\n    }\n}","Null-unchecked version","If you are sure the pointer can never be null and are looking for some kind of\nas_ref_unchecked that returns the &T instead of `Option<&T>, know that you can\ndereference the pointer directly.","let ptr: *const u8 = &10u8 as *const u8;\n\nunsafe {\n    let val_back = &*ptr;\n    println!(\"We got back the value: {}!\", val_back);\n}"]}},{"name":"pub unsafe fn offset(self, count: isize) -> *const T","details":{"description":["Calculates the offset from a pointer.","count is in units of T; e.g. a count of 3 represents a pointer offset of 3 * size_of::<T>() bytes.","Safety","If any of the following conditions are violated, the result is Undefined Behavior:","Both the starting and resulting pointer must be either in bounds or one byte past the end of the same allocated object. The computed offset, in bytes, cannot overflow an isize. The offset being in bounds cannot rely on \"wrapping around\" the address space. That is, the infinite-precision sum, in bytes must fit in a usize.","The compiler and standard library generally tries to ensure allocations never reach a size where an offset is a concern. For instance, Vec and Box ensure they never allocate more than isize::MAX bytes, so vec.as_ptr().add(vec.len()) is always safe.","Most platforms fundamentally can't even construct such an allocation. For instance, no known 64-bit platform can ever serve a request for 263 bytes due to page-table limitations or splitting the address space. However, some 32-bit and 16-bit platforms may successfully serve a request for more than isize::MAX bytes with things like Physical Address Extension. As such, memory acquired directly from allocators or memory mapped files may be too large to handle with this function.","Consider using wrapping_offset instead if these constraints are difficult to satisfy. The only advantage of this method is that it enables more aggressive compiler optimizations."],"example":["Basic usage:","let s: &str = \"123\";\nlet ptr: *const u8 = s.as_ptr();\n\nunsafe {\n    println!(\"{}\", *ptr.offset(1) as char);\n    println!(\"{}\", *ptr.offset(2) as char);\n}"]}},{"name":"pub fn wrapping_offset(self, count: isize) -> *const T","details":{"description":["Calculates the offset from a pointer using wrapping arithmetic.","count is in units of T; e.g. a count of 3 represents a pointer offset of 3 * size_of::<T>() bytes.","Safety","The resulting pointer does not need to be in bounds, but it is potentially hazardous to dereference (which requires unsafe). In particular, the resulting pointer may not be used to access a different allocated object than the one self points to. In other words, x.wrapping_offset(y.wrapping_offset_from(x)) is not the same as y, and dereferencing it is undefined behavior unless x and y point into the same allocated object.","Always use .offset(count) instead when possible, because offset allows the compiler to optimize better. If you need to cross object boundaries, cast the pointer to an integer and do the arithmetic there."],"example":["Basic usage:","// Iterate using a raw pointer in increments of two elements\nlet data = [1u8, 2, 3, 4, 5];\nlet mut ptr: *const u8 = data.as_ptr();\nlet step = 2;\nlet end_rounded_up = ptr.wrapping_offset(6);\n\n// This loop prints \"1, 3, 5, \"\nwhile ptr != end_rounded_up {\n    unsafe {\n        print!(\"{}, \", *ptr);\n    }\n    ptr = ptr.wrapping_offset(step);\n}"]}},{"name":"pub unsafe fn offset_from(self, origin: *const T) -> isize","stability":["ðŸ”¬ This is a nightly-only experimental API.  (ptr_offset_from #41079)"]},{"name":"pub fn wrapping_offset_from(self, origin: *const T) -> isize","stability":["ðŸ”¬ This is a nightly-only experimental API.  (ptr_wrapping_offset_from #41079)"]},{"name":"pub unsafe fn add(self, count: usize) -> *const T","details":{"description":["Calculates the offset from a pointer (convenience for .offset(count as isize)).","count is in units of T; e.g. a count of 3 represents a pointer offset of 3 * size_of::<T>() bytes.","Safety","If any of the following conditions are violated, the result is Undefined Behavior:","Both the starting and resulting pointer must be either in bounds or one byte past the end of an allocated object. The computed offset, in bytes, cannot overflow an isize. The offset being in bounds cannot rely on \"wrapping around\" the address space. That is, the infinite-precision sum must fit in a usize.","The compiler and standard library generally tries to ensure allocations never reach a size where an offset is a concern. For instance, Vec and Box ensure they never allocate more than isize::MAX bytes, so vec.as_ptr().add(vec.len()) is always safe.","Most platforms fundamentally can't even construct such an allocation. For instance, no known 64-bit platform can ever serve a request for 263 bytes due to page-table limitations or splitting the address space. However, some 32-bit and 16-bit platforms may successfully serve a request for more than isize::MAX bytes with things like Physical Address Extension. As such, memory acquired directly from allocators or memory mapped files may be too large to handle with this function.","Consider using wrapping_offset instead if these constraints are difficult to satisfy. The only advantage of this method is that it enables more aggressive compiler optimizations."],"example":["Basic usage:","let s: &str = \"123\";\nlet ptr: *const u8 = s.as_ptr();\n\nunsafe {\n    println!(\"{}\", *ptr.add(1) as char);\n    println!(\"{}\", *ptr.add(2) as char);\n}"]}},{"name":"pub unsafe fn sub(self, count: usize) -> *const T","details":{"description":["Calculates the offset from a pointer (convenience for .offset((count as isize).wrapping_neg())).","count is in units of T; e.g. a count of 3 represents a pointer offset of 3 * size_of::<T>() bytes.","Safety","If any of the following conditions are violated, the result is Undefined Behavior:","Both the starting and resulting pointer must be either in bounds or one byte past the end of an allocated object. The computed offset cannot exceed isize::MAX bytes. The offset being in bounds cannot rely on \"wrapping around\" the address space. That is, the infinite-precision sum must fit in a usize.","The compiler and standard library generally tries to ensure allocations never reach a size where an offset is a concern. For instance, Vec and Box ensure they never allocate more than isize::MAX bytes, so vec.as_ptr().add(vec.len()).sub(vec.len()) is always safe.","Most platforms fundamentally can't even construct such an allocation. For instance, no known 64-bit platform can ever serve a request for 263 bytes due to page-table limitations or splitting the address space. However, some 32-bit and 16-bit platforms may successfully serve a request for more than isize::MAX bytes with things like Physical Address Extension. As such, memory acquired directly from allocators or memory mapped files may be too large to handle with this function.","Consider using wrapping_offset instead if these constraints are difficult to satisfy. The only advantage of this method is that it enables more aggressive compiler optimizations."],"example":["Basic usage:","let s: &str = \"123\";\n\nunsafe {\n    let end: *const u8 = s.as_ptr().add(3);\n    println!(\"{}\", *end.sub(1) as char);\n    println!(\"{}\", *end.sub(2) as char);\n}"]}},{"name":"pub fn wrapping_add(self, count: usize) -> *const T","details":{"description":["Calculates the offset from a pointer using wrapping arithmetic. (convenience for .wrapping_offset(count as isize))","count is in units of T; e.g. a count of 3 represents a pointer offset of 3 * size_of::<T>() bytes.","Safety","The resulting pointer does not need to be in bounds, but it is potentially hazardous to dereference (which requires unsafe).","Always use .add(count) instead when possible, because add allows the compiler to optimize better."],"example":["Basic usage:","// Iterate using a raw pointer in increments of two elements\nlet data = [1u8, 2, 3, 4, 5];\nlet mut ptr: *const u8 = data.as_ptr();\nlet step = 2;\nlet end_rounded_up = ptr.wrapping_add(6);\n\n// This loop prints \"1, 3, 5, \"\nwhile ptr != end_rounded_up {\n    unsafe {\n        print!(\"{}, \", *ptr);\n    }\n    ptr = ptr.wrapping_add(step);\n}"]}},{"name":"pub fn wrapping_sub(self, count: usize) -> *const T","details":{"description":["Calculates the offset from a pointer using wrapping arithmetic. (convenience for .wrapping_offset((count as isize).wrapping_sub()))","count is in units of T; e.g. a count of 3 represents a pointer offset of 3 * size_of::<T>() bytes.","Safety","The resulting pointer does not need to be in bounds, but it is potentially hazardous to dereference (which requires unsafe).","Always use .sub(count) instead when possible, because sub allows the compiler to optimize better."],"example":["Basic usage:","// Iterate using a raw pointer in increments of two elements (backwards)\nlet data = [1u8, 2, 3, 4, 5];\nlet mut ptr: *const u8 = data.as_ptr();\nlet start_rounded_down = ptr.wrapping_sub(2);\nptr = ptr.wrapping_add(4);\nlet step = 2;\n// This loop prints \"5, 3, 1, \"\nwhile ptr != start_rounded_down {\n    unsafe {\n        print!(\"{}, \", *ptr);\n    }\n    ptr = ptr.wrapping_sub(step);\n}"]}},{"name":"pub unsafe fn read(self) -> T","details":{"description":["Reads the value from self without moving it. This leaves the memory in self unchanged.","Safety","Beyond accepting a raw pointer, this is unsafe because it semantically moves the value out of self without preventing further usage of self. If T is not Copy, then care must be taken to ensure that the value at self is not used before the data is overwritten again (e.g. with write, write_bytes, or copy). Note that *self = foo counts as a use because it will attempt to drop the value previously at *self.","The pointer must be aligned; use read_unaligned if that is not the case."],"example":["Basic usage:","let x = 12;\nlet y = &x as *const i32;\n\nunsafe {\n    assert_eq!(y.read(), 12);\n}"]}},{"name":"pub unsafe fn read_volatile(self) -> T","details":{"description":["Performs a volatile read of the value from self without moving it. This leaves the memory in self unchanged.","Volatile operations are intended to act on I/O memory, and are guaranteed to not be elided or reordered by the compiler across other volatile operations.","Notes","Rust does not currently have a rigorously and formally defined memory model, so the precise semantics of what \"volatile\" means here is subject to change over time. That being said, the semantics will almost always end up pretty similar to C11's definition of volatile.","The compiler shouldn't change the relative order or number of volatile memory operations. However, volatile memory operations on zero-sized types (e.g. if a zero-sized type is passed to read_volatile) are no-ops and may be ignored.","Safety","Beyond accepting a raw pointer, this is unsafe because it semantically moves the value out of self without preventing further usage of self. If T is not Copy, then care must be taken to ensure that the value at self is not used before the data is overwritten again (e.g. with write, write_bytes, or copy). Note that *self = foo counts as a use because it will attempt to drop the value previously at *self.","Just like in C, whether an operation is volatile has no bearing whatsoever on questions involving concurrent access from multiple threads. Volatile accesses behave exactly like non-atomic accesses in that regard. In particular, a race between a read_volatile and any write operation to the same location is undefined behavior."],"example":["Basic usage:","let x = 12;\nlet y = &x as *const i32;\n\nunsafe {\n    assert_eq!(y.read_volatile(), 12);\n}"]}},{"name":"pub unsafe fn read_unaligned(self) -> T","details":{"description":["Reads the value from self without moving it. This leaves the memory in self unchanged.","Unlike read, the pointer may be unaligned.","Safety","Beyond accepting a raw pointer, this is unsafe because it semantically moves the value out of self without preventing further usage of self. If T is not Copy, then care must be taken to ensure that the value at self is not used before the data is overwritten again (e.g. with write, write_bytes, or copy). Note that *self = foo counts as a use because it will attempt to drop the value previously at *self."],"example":["Basic usage:","let x = 12;\nlet y = &x as *const i32;\n\nunsafe {\n    assert_eq!(y.read_unaligned(), 12);\n}"]}},{"name":"pub unsafe fn copy_to(self, dest: *mut T, count: usize)","details":{"description":["Copies count * size_of<T> bytes from self to dest. The source and destination may overlap.","NOTE: this has the same argument order as ptr::copy.","This is semantically equivalent to C's memmove.","Safety","Care must be taken with the ownership of self and dest. This method semantically moves the values of self into dest. However it does not drop the contents of dest, or prevent the contents of self from being dropped or used."],"example":["Efficiently create a Rust vector from an unsafe buffer:","unsafe fn from_buf_raw<T: Copy>(ptr: *const T, elts: usize) -> Vec<T> {\n    let mut dst = Vec::with_capacity(elts);\n    dst.set_len(elts);\n    ptr.copy_to(dst.as_mut_ptr(), elts);\n    dst\n}"]}},{"name":"pub unsafe fn copy_to_nonoverlapping(self, dest: *mut T, count: usize)","details":{"description":["Copies count * size_of<T> bytes from self to dest. The source and destination may not overlap.","NOTE: this has the same argument order as ptr::copy_nonoverlapping.","copy_nonoverlapping is semantically equivalent to C's memcpy.","Safety","Beyond requiring that the program must be allowed to access both regions of memory, it is Undefined Behavior for source and destination to overlap. Care must also be taken with the ownership of self and self. This method semantically moves the values of self into dest. However it does not drop the contents of dest, or prevent the contents of self from being dropped or used."],"example":["Efficiently create a Rust vector from an unsafe buffer:","unsafe fn from_buf_raw<T: Copy>(ptr: *const T, elts: usize) -> Vec<T> {\n    let mut dst = Vec::with_capacity(elts);\n    dst.set_len(elts);\n    ptr.copy_to_nonoverlapping(dst.as_mut_ptr(), elts);\n    dst\n}"]}},{"name":"pub fn align_offset(self, align: usize) -> usize","stability":["ðŸ”¬ This is a nightly-only experimental API.  (align_offset #44488)"]},{"name":"pub fn is_null(self) -> bool","details":{"description":["Returns true if the pointer is null.","Note that unsized types have many possible null pointers, as only the raw data pointer is considered, not their length, vtable, etc. Therefore, two pointers that are null may still not compare equal to each other."],"example":["Basic usage:","let mut s = [1, 2, 3];\nlet ptr: *mut u32 = s.as_mut_ptr();\nassert!(!ptr.is_null());"]}},{"name":"pub unsafe fn as_ref<'a>(self) -> Option<&'a T>","details":{"description":["Returns None if the pointer is null, or else returns a reference to the value wrapped in Some.","Safety","While this method and its mutable counterpart are useful for null-safety, it is important to note that this is still an unsafe operation because the returned value could be pointing to invalid memory.","Additionally, the lifetime 'a returned is arbitrarily chosen and does not necessarily reflect the actual lifetime of the data."],"example":["Basic usage:","let ptr: *mut u8 = &mut 10u8 as *mut u8;\n\nunsafe {\n    if let Some(val_back) = ptr.as_ref() {\n        println!(\"We got back the value: {}!\", val_back);\n    }\n}","Null-unchecked version","If you are sure the pointer can never be null and are looking for some kind of\nas_ref_unchecked that returns the &T instead of `Option<&T>, know that you can\ndereference the pointer directly.","let ptr: *mut u8 = &mut 10u8 as *mut u8;\n\nunsafe {\n    let val_back = &*ptr;\n    println!(\"We got back the value: {}!\", val_back);\n}"]}},{"name":"pub unsafe fn offset(self, count: isize) -> *mut T","details":{"description":["Calculates the offset from a pointer.","count is in units of T; e.g. a count of 3 represents a pointer offset of 3 * size_of::<T>() bytes.","Safety","If any of the following conditions are violated, the result is Undefined Behavior:","Both the starting and resulting pointer must be either in bounds or one byte past the end of the same allocated object. The computed offset, in bytes, cannot overflow an isize. The offset being in bounds cannot rely on \"wrapping around\" the address space. That is, the infinite-precision sum, in bytes must fit in a usize.","The compiler and standard library generally tries to ensure allocations never reach a size where an offset is a concern. For instance, Vec and Box ensure they never allocate more than isize::MAX bytes, so vec.as_ptr().add(vec.len()) is always safe.","Most platforms fundamentally can't even construct such an allocation. For instance, no known 64-bit platform can ever serve a request for 263 bytes due to page-table limitations or splitting the address space. However, some 32-bit and 16-bit platforms may successfully serve a request for more than isize::MAX bytes with things like Physical Address Extension. As such, memory acquired directly from allocators or memory mapped files may be too large to handle with this function.","Consider using wrapping_offset instead if these constraints are difficult to satisfy. The only advantage of this method is that it enables more aggressive compiler optimizations."],"example":["Basic usage:","let mut s = [1, 2, 3];\nlet ptr: *mut u32 = s.as_mut_ptr();\n\nunsafe {\n    println!(\"{}\", *ptr.offset(1));\n    println!(\"{}\", *ptr.offset(2));\n}"]}},{"name":"pub fn wrapping_offset(self, count: isize) -> *mut T","details":{"description":["Calculates the offset from a pointer using wrapping arithmetic. count is in units of T; e.g. a count of 3 represents a pointer offset of 3 * size_of::<T>() bytes.","Safety","The resulting pointer does not need to be in bounds, but it is potentially hazardous to dereference (which requires unsafe). In particular, the resulting pointer may not be used to access a different allocated object than the one self points to. In other words, x.wrapping_offset(y.wrapping_offset_from(x)) is not the same as y, and dereferencing it is undefined behavior unless x and y point into the same allocated object.","Always use .offset(count) instead when possible, because offset allows the compiler to optimize better. If you need to cross object boundaries, cast the pointer to an integer and do the arithmetic there."],"example":["Basic usage:","// Iterate using a raw pointer in increments of two elements\nlet mut data = [1u8, 2, 3, 4, 5];\nlet mut ptr: *mut u8 = data.as_mut_ptr();\nlet step = 2;\nlet end_rounded_up = ptr.wrapping_offset(6);\n\nwhile ptr != end_rounded_up {\n    unsafe {\n        *ptr = 0;\n    }\n    ptr = ptr.wrapping_offset(step);\n}\nassert_eq!(&data, &[0, 2, 0, 4, 0]);"]}},{"name":"pub unsafe fn as_mut<'a>(self) -> Option<&'a mut T>","details":{"description":["Returns None if the pointer is null, or else returns a mutable reference to the value wrapped in Some.","Safety","As with as_ref, this is unsafe because it cannot verify the validity of the returned pointer, nor can it ensure that the lifetime 'a returned is indeed a valid lifetime for the contained data."],"example":["Basic usage:","let mut s = [1, 2, 3];\nlet ptr: *mut u32 = s.as_mut_ptr();\nlet first_value = unsafe { ptr.as_mut().unwrap() };\n*first_value = 4;\nprintln!(\"{:?}\", s); // It'll print: \"[4, 2, 3]\"."]}},{"name":"pub unsafe fn offset_from(self, origin: *const T) -> isize","stability":["ðŸ”¬ This is a nightly-only experimental API.  (ptr_offset_from #41079)"]},{"name":"pub fn wrapping_offset_from(self, origin: *const T) -> isize","stability":["ðŸ”¬ This is a nightly-only experimental API.  (ptr_wrapping_offset_from #41079)"]},{"name":"pub unsafe fn add(self, count: usize) -> *mut T","details":{"description":["Calculates the offset from a pointer (convenience for .offset(count as isize)).","count is in units of T; e.g. a count of 3 represents a pointer offset of 3 * size_of::<T>() bytes.","Safety","If any of the following conditions are violated, the result is Undefined Behavior:","Both the starting and resulting pointer must be either in bounds or one byte past the end of an allocated object. The computed offset, in bytes, cannot overflow an isize. The offset being in bounds cannot rely on \"wrapping around\" the address space. That is, the infinite-precision sum must fit in a usize.","The compiler and standard library generally tries to ensure allocations never reach a size where an offset is a concern. For instance, Vec and Box ensure they never allocate more than isize::MAX bytes, so vec.as_ptr().add(vec.len()) is always safe.","Most platforms fundamentally can't even construct such an allocation. For instance, no known 64-bit platform can ever serve a request for 263 bytes due to page-table limitations or splitting the address space. However, some 32-bit and 16-bit platforms may successfully serve a request for more than isize::MAX bytes with things like Physical Address Extension. As such, memory acquired directly from allocators or memory mapped files may be too large to handle with this function.","Consider using wrapping_offset instead if these constraints are difficult to satisfy. The only advantage of this method is that it enables more aggressive compiler optimizations."],"example":["Basic usage:","let s: &str = \"123\";\nlet ptr: *const u8 = s.as_ptr();\n\nunsafe {\n    println!(\"{}\", *ptr.add(1) as char);\n    println!(\"{}\", *ptr.add(2) as char);\n}"]}},{"name":"pub unsafe fn sub(self, count: usize) -> *mut T","details":{"description":["Calculates the offset from a pointer (convenience for .offset((count as isize).wrapping_neg())).","count is in units of T; e.g. a count of 3 represents a pointer offset of 3 * size_of::<T>() bytes.","Safety","If any of the following conditions are violated, the result is Undefined Behavior:","Both the starting and resulting pointer must be either in bounds or one byte past the end of an allocated object. The computed offset cannot exceed isize::MAX bytes. The offset being in bounds cannot rely on \"wrapping around\" the address space. That is, the infinite-precision sum must fit in a usize.","The compiler and standard library generally tries to ensure allocations never reach a size where an offset is a concern. For instance, Vec and Box ensure they never allocate more than isize::MAX bytes, so vec.as_ptr().add(vec.len()).sub(vec.len()) is always safe.","Most platforms fundamentally can't even construct such an allocation. For instance, no known 64-bit platform can ever serve a request for 263 bytes due to page-table limitations or splitting the address space. However, some 32-bit and 16-bit platforms may successfully serve a request for more than isize::MAX bytes with things like Physical Address Extension. As such, memory acquired directly from allocators or memory mapped files may be too large to handle with this function.","Consider using wrapping_offset instead if these constraints are difficult to satisfy. The only advantage of this method is that it enables more aggressive compiler optimizations."],"example":["Basic usage:","let s: &str = \"123\";\n\nunsafe {\n    let end: *const u8 = s.as_ptr().add(3);\n    println!(\"{}\", *end.sub(1) as char);\n    println!(\"{}\", *end.sub(2) as char);\n}"]}},{"name":"pub fn wrapping_add(self, count: usize) -> *mut T","details":{"description":["Calculates the offset from a pointer using wrapping arithmetic. (convenience for .wrapping_offset(count as isize))","count is in units of T; e.g. a count of 3 represents a pointer offset of 3 * size_of::<T>() bytes.","Safety","The resulting pointer does not need to be in bounds, but it is potentially hazardous to dereference (which requires unsafe).","Always use .add(count) instead when possible, because add allows the compiler to optimize better."],"example":["Basic usage:","// Iterate using a raw pointer in increments of two elements\nlet data = [1u8, 2, 3, 4, 5];\nlet mut ptr: *const u8 = data.as_ptr();\nlet step = 2;\nlet end_rounded_up = ptr.wrapping_add(6);\n\n// This loop prints \"1, 3, 5, \"\nwhile ptr != end_rounded_up {\n    unsafe {\n        print!(\"{}, \", *ptr);\n    }\n    ptr = ptr.wrapping_add(step);\n}"]}},{"name":"pub fn wrapping_sub(self, count: usize) -> *mut T","details":{"description":["Calculates the offset from a pointer using wrapping arithmetic. (convenience for .wrapping_offset((count as isize).wrapping_sub()))","count is in units of T; e.g. a count of 3 represents a pointer offset of 3 * size_of::<T>() bytes.","Safety","The resulting pointer does not need to be in bounds, but it is potentially hazardous to dereference (which requires unsafe).","Always use .sub(count) instead when possible, because sub allows the compiler to optimize better."],"example":["Basic usage:","// Iterate using a raw pointer in increments of two elements (backwards)\nlet data = [1u8, 2, 3, 4, 5];\nlet mut ptr: *const u8 = data.as_ptr();\nlet start_rounded_down = ptr.wrapping_sub(2);\nptr = ptr.wrapping_add(4);\nlet step = 2;\n// This loop prints \"5, 3, 1, \"\nwhile ptr != start_rounded_down {\n    unsafe {\n        print!(\"{}, \", *ptr);\n    }\n    ptr = ptr.wrapping_sub(step);\n}"]}},{"name":"pub unsafe fn read(self) -> T","details":{"description":["Reads the value from self without moving it. This leaves the memory in self unchanged.","Safety","Beyond accepting a raw pointer, this is unsafe because it semantically moves the value out of self without preventing further usage of self. If T is not Copy, then care must be taken to ensure that the value at self is not used before the data is overwritten again (e.g. with write, write_bytes, or copy). Note that *self = foo counts as a use because it will attempt to drop the value previously at *self.","The pointer must be aligned; use read_unaligned if that is not the case."],"example":["Basic usage:","let x = 12;\nlet y = &x as *const i32;\n\nunsafe {\n    assert_eq!(y.read(), 12);\n}"]}},{"name":"pub unsafe fn read_volatile(self) -> T","details":{"description":["Performs a volatile read of the value from self without moving it. This leaves the memory in self unchanged.","Volatile operations are intended to act on I/O memory, and are guaranteed to not be elided or reordered by the compiler across other volatile operations.","Notes","Rust does not currently have a rigorously and formally defined memory model, so the precise semantics of what \"volatile\" means here is subject to change over time. That being said, the semantics will almost always end up pretty similar to C11's definition of volatile.","The compiler shouldn't change the relative order or number of volatile memory operations. However, volatile memory operations on zero-sized types (e.g. if a zero-sized type is passed to read_volatile) are no-ops and may be ignored.","Safety","Beyond accepting a raw pointer, this is unsafe because it semantically moves the value out of self without preventing further usage of self. If T is not Copy, then care must be taken to ensure that the value at self is not used before the data is overwritten again (e.g. with write, write_bytes, or copy). Note that *self = foo counts as a use because it will attempt to drop the value previously at *self.","Just like in C, whether an operation is volatile has no bearing whatsoever on questions involving concurrent access from multiple threads. Volatile accesses behave exactly like non-atomic accesses in that regard. In particular, a race between a read_volatile and any write operation to the same location is undefined behavior."],"example":["Basic usage:","let x = 12;\nlet y = &x as *const i32;\n\nunsafe {\n    assert_eq!(y.read_volatile(), 12);\n}"]}},{"name":"pub unsafe fn read_unaligned(self) -> T","details":{"description":["Reads the value from self without moving it. This leaves the memory in self unchanged.","Unlike read, the pointer may be unaligned.","Safety","Beyond accepting a raw pointer, this is unsafe because it semantically moves the value out of self without preventing further usage of self. If T is not Copy, then care must be taken to ensure that the value at self is not used before the data is overwritten again (e.g. with write, write_bytes, or copy). Note that *self = foo counts as a use because it will attempt to drop the value previously at *self."],"example":["Basic usage:","let x = 12;\nlet y = &x as *const i32;\n\nunsafe {\n    assert_eq!(y.read_unaligned(), 12);\n}"]}},{"name":"pub unsafe fn copy_to(self, dest: *mut T, count: usize)","details":{"description":["Copies count * size_of<T> bytes from self to dest. The source and destination may overlap.","NOTE: this has the same argument order as ptr::copy.","This is semantically equivalent to C's memmove.","Safety","Care must be taken with the ownership of self and dest. This method semantically moves the values of self into dest. However it does not drop the contents of self, or prevent the contents of dest from being dropped or used."],"example":["Efficiently create a Rust vector from an unsafe buffer:","unsafe fn from_buf_raw<T: Copy>(ptr: *const T, elts: usize) -> Vec<T> {\n    let mut dst = Vec::with_capacity(elts);\n    dst.set_len(elts);\n    ptr.copy_to(dst.as_mut_ptr(), elts);\n    dst\n}"]}},{"name":"pub unsafe fn copy_to_nonoverlapping(self, dest: *mut T, count: usize)","details":{"description":["Copies count * size_of<T> bytes from self to dest. The source and destination may not overlap.","NOTE: this has the same argument order as ptr::copy_nonoverlapping.","copy_nonoverlapping is semantically equivalent to C's memcpy.","Safety","Beyond requiring that the program must be allowed to access both regions of memory, it is Undefined Behavior for source and destination to overlap. Care must also be taken with the ownership of self and self. This method semantically moves the values of self into dest. However it does not drop the contents of dest, or prevent the contents of self from being dropped or used."],"example":["Efficiently create a Rust vector from an unsafe buffer:","unsafe fn from_buf_raw<T: Copy>(ptr: *const T, elts: usize) -> Vec<T> {\n    let mut dst = Vec::with_capacity(elts);\n    dst.set_len(elts);\n    ptr.copy_to_nonoverlapping(dst.as_mut_ptr(), elts);\n    dst\n}"]}},{"name":"pub unsafe fn copy_from(self, src: *const T, count: usize)","details":{"description":["Copies count * size_of<T> bytes from src to self. The source and destination may overlap.","NOTE: this has the opposite argument order of ptr::copy.","This is semantically equivalent to C's memmove.","Safety","Care must be taken with the ownership of src and self. This method semantically moves the values of src into self. However it does not drop the contents of self, or prevent the contents of src from being dropped or used."],"example":["Efficiently create a Rust vector from an unsafe buffer:","unsafe fn from_buf_raw<T: Copy>(ptr: *const T, elts: usize) -> Vec<T> {\n    let mut dst: Vec<T> = Vec::with_capacity(elts);\n    dst.set_len(elts);\n    dst.as_mut_ptr().copy_from(ptr, elts);\n    dst\n}"]}},{"name":"pub unsafe fn copy_from_nonoverlapping(self, src: *const T, count: usize)","details":{"description":["Copies count * size_of<T> bytes from src to self. The source and destination may not overlap.","NOTE: this has the opposite argument order of ptr::copy_nonoverlapping.","copy_nonoverlapping is semantically equivalent to C's memcpy.","Safety","Beyond requiring that the program must be allowed to access both regions of memory, it is Undefined Behavior for source and destination to overlap. Care must also be taken with the ownership of src and self. This method semantically moves the values of src into self. However it does not drop the contents of self, or prevent the contents of src from being dropped or used."],"example":["Efficiently create a Rust vector from an unsafe buffer:","unsafe fn from_buf_raw<T: Copy>(ptr: *const T, elts: usize) -> Vec<T> {\n    let mut dst: Vec<T> = Vec::with_capacity(elts);\n    dst.set_len(elts);\n    dst.as_mut_ptr().copy_from_nonoverlapping(ptr, elts);\n    dst\n}"]}},{"name":"pub unsafe fn drop_in_place(self)","details":{"description":["Executes the destructor (if any) of the pointed-to value.","This has two use cases:","It is required to use drop_in_place to drop unsized types like trait objects, because they can't be read out onto the stack and dropped normally. It is friendlier to the optimizer to do this over ptr::read when dropping manually allocated memory (e.g. when writing Box/Rc/Vec), as the compiler doesn't need to prove that it's sound to elide the copy.","Safety","This has all the same safety problems as ptr::read with respect to invalid pointers, types, and double drops."]}},{"name":"pub unsafe fn write(self, val: T)","details":{"description":["Overwrites a memory location with the given value without reading or dropping the old value.","Safety","This operation is marked unsafe because it writes through a raw pointer.","It does not drop the contents of self. This is safe, but it could leak allocations or resources, so care must be taken not to overwrite an object that should be dropped.","Additionally, it does not drop val. Semantically, val is moved into the location pointed to by self.","This is appropriate for initializing uninitialized memory, or overwriting memory that has previously been read from.","The pointer must be aligned; use write_unaligned if that is not the case."],"example":["Basic usage:","let mut x = 0;\nlet y = &mut x as *mut i32;\nlet z = 12;\n\nunsafe {\n    y.write(z);\n    assert_eq!(y.read(), 12);\n}"]}},{"name":"pub unsafe fn write_bytes(self, val: u8, count: usize)","details":{"description":["Invokes memset on the specified pointer, setting count * size_of::<T>() bytes of memory starting at self to val."],"example":["let mut vec = vec![0; 4];\nunsafe {\n    let vec_ptr = vec.as_mut_ptr();\n    vec_ptr.write_bytes(b'a', 2);\n}\nassert_eq!(vec, [b'a', b'a', 0, 0]);"]}},{"name":"pub unsafe fn write_volatile(self, val: T)","details":{"description":["Performs a volatile write of a memory location with the given value without reading or dropping the old value.","Volatile operations are intended to act on I/O memory, and are guaranteed to not be elided or reordered by the compiler across other volatile operations.","Notes","Rust does not currently have a rigorously and formally defined memory model, so the precise semantics of what \"volatile\" means here is subject to change over time. That being said, the semantics will almost always end up pretty similar to C11's definition of volatile.","The compiler shouldn't change the relative order or number of volatile memory operations. However, volatile memory operations on zero-sized types (e.g. if a zero-sized type is passed to write_volatile) are no-ops and may be ignored.","Safety","This operation is marked unsafe because it accepts a raw pointer.","It does not drop the contents of self. This is safe, but it could leak allocations or resources, so care must be taken not to overwrite an object that should be dropped.","This is appropriate for initializing uninitialized memory, or overwriting memory that has previously been read from.","Just like in C, whether an operation is volatile has no bearing whatsoever on questions involving concurrent access from multiple threads. Volatile accesses behave exactly like non-atomic accesses in that regard. In particular, a race between a write_volatile and any other operation (reading or writing) on the same location is undefined behavior."],"example":["Basic usage:","let mut x = 0;\nlet y = &mut x as *mut i32;\nlet z = 12;\n\nunsafe {\n    y.write_volatile(z);\n    assert_eq!(y.read_volatile(), 12);\n}"]}},{"name":"pub unsafe fn write_unaligned(self, val: T)","details":{"description":["Overwrites a memory location with the given value without reading or dropping the old value.","Unlike write, the pointer may be unaligned.","Safety","This operation is marked unsafe because it writes through a raw pointer.","It does not drop the contents of self. This is safe, but it could leak allocations or resources, so care must be taken not to overwrite an object that should be dropped.","Additionally, it does not drop self. Semantically, self is moved into the location pointed to by val.","This is appropriate for initializing uninitialized memory, or overwriting memory that has previously been read from."],"example":["Basic usage:","let mut x = 0;\nlet y = &mut x as *mut i32;\nlet z = 12;\n\nunsafe {\n    y.write_unaligned(z);\n    assert_eq!(y.read_unaligned(), 12);\n}"]}},{"name":"pub unsafe fn replace(self, src: T) -> T","details":{"description":["Replaces the value at self with src, returning the old value, without dropping either.","Safety","This is only unsafe because it accepts a raw pointer. Otherwise, this operation is identical to mem::replace."]}},{"name":"pub unsafe fn swap(self, with: *mut T)","details":{"description":["Swaps the values at two mutable locations of the same type, without deinitializing either. They may overlap, unlike mem::swap which is otherwise equivalent.","Safety","This function copies the memory through the raw pointers passed to it as arguments.","Ensure that these pointers are valid before calling swap."]}},{"name":"pub fn align_offset(self, align: usize) -> usize","stability":["ðŸ”¬ This is a nightly-only experimental API.  (align_offset #44488)"]}]}